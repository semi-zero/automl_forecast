{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7543dba6-7607-41f2-8ba1-8413e7ea1cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install tensorflow-estimator=2.1.0\n",
    "#!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "32e9f4e6-c402-404f-bc15-6628f63a2691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "from loggers import logger\n",
    "\n",
    "from process import input_data, preprocess\n",
    "\n",
    "def set_logger(log_name):\n",
    "    log_obj = logger.AutoMLLog(log_name)\n",
    "    log_obj.set_handler('automl_process')\n",
    "    log_obj.set_formats()\n",
    "    auto_logger = log_obj.addOn()\n",
    "    \n",
    "    auto_logger.info('logger 세팅')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "94a12216-b764-4f33-a2fa-295a134aabd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # avoid printing out absolute paths\n",
    "\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c7f9625-53cf-414a-be47-08cd7be94773",
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='storage/stallion.csv'\n",
    "target_var='volume'\n",
    "date_var= 'date'\n",
    "store_list=['sku','agency']\n",
    "unit='month'\n",
    "predict_n = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "aef51c8e-34cb-4eb4-8997-841b310933e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='storage/Walmart.csv'\n",
    "target_var='Weekly_Sales'\n",
    "date_var= 'Date'\n",
    "store_list=['Store']\n",
    "unit='week'\n",
    "predict_n = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b4934c26-89a2-40bc-86cc-416898486e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='storage/demand_forecast_dataset.csv'\n",
    "target_var='sale_qty'\n",
    "date_var= 'sale_dy'\n",
    "store_list=['str_cd', 'prod_cd']\n",
    "unit='day'\n",
    "predict_n = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b1e0f053-88ce-4583-a588-2e6911f330b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TensorBoardLogger' object has no attribute 'AutoMLLog'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10572\\4219253662.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlog_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'practice_tft'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mset_logger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mData_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_var\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdate_var\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdate_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstore_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstore_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0munit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10572\\2659849918.py\u001b[0m in \u001b[0;36mset_logger\u001b[1;34m(log_name)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mset_logger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mlog_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAutoMLLog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mlog_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_handler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'automl_process'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mlog_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_formats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TensorBoardLogger' object has no attribute 'AutoMLLog'"
     ]
    }
   ],
   "source": [
    "log_name = 'practice_tft'\n",
    "set_logger(log_name)\n",
    "data, var_list, num_var, obj_var = input_data.Data_load(path, log_name).read_data()\n",
    "df = preprocess.Preprocessing(log_name, data, var_list, num_var, obj_var, target_var=target_var, date_var=date_var, store_list=store_list, unit=unit).df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9c23a4ea-4694-4086-836d-f1de708e02bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add additional features\n",
    "#data[\"month\"] = data.date.dt.month.astype(str).astype(\"category\")  # categories have be strings # 이미 함\n",
    "df[f\"log_{target_var}\"] = np.log(df[target_var] + 1e-4)\n",
    "for store_var in store_list:\n",
    "    df[f\"avg_{target_var}_by_{store_var}\"] = df.groupby([\"time_idx\", store_var], observed=True)[target_var].transform(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5aadda67-bda3-46f0-b056-cbbd77fb21af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Holiday_Flag</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Date</th>\n",
       "      <th>Store</th>\n",
       "      <th>dummy</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>week</th>\n",
       "      <th>log_Weekly_Sales</th>\n",
       "      <th>avg_Weekly_Sales_by_Store</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.607910</td>\n",
       "      <td>-1.644531</td>\n",
       "      <td>1.017578</td>\n",
       "      <td>-0.085022</td>\n",
       "      <td>-0.27417</td>\n",
       "      <td>1453329.500</td>\n",
       "      <td>2010-01-10</td>\n",
       "      <td>1</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.189367</td>\n",
       "      <td>1453329.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.087708</td>\n",
       "      <td>-1.393555</td>\n",
       "      <td>0.998047</td>\n",
       "      <td>-0.101624</td>\n",
       "      <td>-0.27417</td>\n",
       "      <td>1594968.250</td>\n",
       "      <td>2010-02-04</td>\n",
       "      <td>1</td>\n",
       "      <td>dummy</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>14.282365</td>\n",
       "      <td>1594968.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.098633</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>1.007812</td>\n",
       "      <td>-0.114136</td>\n",
       "      <td>-0.27417</td>\n",
       "      <td>1492418.125</td>\n",
       "      <td>2010-02-07</td>\n",
       "      <td>1</td>\n",
       "      <td>dummy</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>14.215908</td>\n",
       "      <td>1492418.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.124023</td>\n",
       "      <td>-1.840820</td>\n",
       "      <td>1.007812</td>\n",
       "      <td>0.058716</td>\n",
       "      <td>-0.27417</td>\n",
       "      <td>1611968.125</td>\n",
       "      <td>2010-02-19</td>\n",
       "      <td>1</td>\n",
       "      <td>dummy</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>14.292967</td>\n",
       "      <td>1611968.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.761230</td>\n",
       "      <td>-1.738281</td>\n",
       "      <td>1.010742</td>\n",
       "      <td>0.058716</td>\n",
       "      <td>-0.27417</td>\n",
       "      <td>1409727.625</td>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>1</td>\n",
       "      <td>dummy</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>14.158907</td>\n",
       "      <td>1409727.625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature  Fuel_Price       CPI  Unemployment  Holiday_Flag  \\\n",
       "0     0.607910   -1.644531  1.017578     -0.085022      -0.27417   \n",
       "1     0.087708   -1.393555  0.998047     -0.101624      -0.27417   \n",
       "2     1.098633   -1.500000  1.007812     -0.114136      -0.27417   \n",
       "3    -1.124023   -1.840820  1.007812      0.058716      -0.27417   \n",
       "4    -0.761230   -1.738281  1.010742      0.058716      -0.27417   \n",
       "\n",
       "   Weekly_Sales       Date Store  dummy  time_idx week  log_Weekly_Sales  \\\n",
       "0   1453329.500 2010-01-10     1  dummy         0    1         14.189367   \n",
       "1   1594968.250 2010-02-04     1  dummy         1    5         14.282365   \n",
       "2   1492418.125 2010-02-07     1  dummy         2    5         14.215908   \n",
       "3   1611968.125 2010-02-19     1  dummy         3    7         14.292967   \n",
       "4   1409727.625 2010-02-26     1  dummy         4    8         14.158907   \n",
       "\n",
       "   avg_Weekly_Sales_by_Store  \n",
       "0                1453329.500  \n",
       "1                1594968.250  \n",
       "2                1492418.125  \n",
       "3                1611968.125  \n",
       "4                1409727.625  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d9faebf7-151f-4d10-bed4-4b514654d4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prediction_length = predict_n\n",
    "max_encoder_length = predict_n * 4\n",
    "training_cutoff = df['time_idx'].max() - max_prediction_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "93d9fda4-5ecd-4de9-b6ee-8418238e8747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#매우 중요\n",
    "df.sort_values(store_list, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "593c2c8d-402c-48cc-bae9-fce722c359ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = TimeSeriesDataSet(\n",
    "    df[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=target_var,\n",
    "    group_ids=store_list,\n",
    "    min_encoder_length=max_encoder_length // 2,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=store_list,\n",
    "    static_reals=[],\n",
    "    time_varying_known_categoricals=[unit],\n",
    "    variable_groups={},  # group of categorical variables can be treated as one variable\n",
    "    time_varying_known_reals=[\"time_idx\"],\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=\n",
    "    [target_var, f\"log_{target_var}\"]+ [f\"avg_{target_var}_by_{store_var}\" for store_var in store_list],\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=store_list, transformation=\"softplus\"\n",
    "    ),  # use softplus and normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    ")\n",
    "\n",
    "# create validation set (predict=True) which means to predict the last max_prediction_length points in time\n",
    "# for each series\n",
    "validation = TimeSeriesDataSet.from_dataset(training, df, predict=True, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size = 128  # set this between 32 to 128\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "488bcf6c-2e1b-4f16-82ff-fb52ade4ed94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 22.0k\n"
     ]
    }
   ],
   "source": [
    "# configure network and trainer\n",
    "pl.seed_everything(42)\n",
    "trainer = pl.Trainer(\n",
    "    gpus=0,\n",
    "    # clipping gradients is a hyperparameter and important to prevent divergance\n",
    "    # of the gradient for recurrent neural networks\n",
    "    gradient_clip_val=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    # not meaningful for finding the learning rate but otherwise very important\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,  # most important hyperparameter apart from learning rate\n",
    "    # number of attention heads. Set to up to 4 for large datasets\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,  # between 0.1 and 0.3 are good values\n",
    "    hidden_continuous_size=8,  # set to <= hidden_size\n",
    "    output_size=7,  # 7 quantiles by default\n",
    "    loss=QuantileLoss(),\n",
    "    # reduce learning rate if no improvement in validation loss after x epochs\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "79da45de-1960-4824-809e-0c8512a9cf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b7c415c402425db32f69fb183bf9c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at C:\\Users\\LDCC\\Desktop\\eco_code\\automl_forecast\\lr_find_temp_model_763cbe4c-1877-4689-8690-d155cc19112f.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suggested learning rate: 0.057543993733715736\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find optimal learning rate\n",
    "res = trainer.tuner.lr_find(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    max_lr=10.0,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2d45aa4e-6638-440d-8e32-a8f8a3d95136",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 22.0k\n"
     ]
    }
   ],
   "source": [
    "# configure network and trainer\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=3,\n",
    "    gpus=0,\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=30,  # coment in for training, running valiation every 30 batches\n",
    "    # fast_dev_run=True,  # comment in to check that networkor dataset has no serious bugs\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    output_size=7,  # 7 quantiles by default\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "71233073-093c-4032-97f6-fe67f4c5881c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 1.4 K \n",
      "3  | prescalers                         | ModuleDict                      | 128   \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 1.9 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 3.3 K \n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 1.3 K \n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K \n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K \n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K \n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K \n",
      "11 | lstm_encoder                       | LSTM                            | 2.2 K \n",
      "12 | lstm_decoder                       | LSTM                            | 2.2 K \n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544   \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 32    \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K \n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 1.1 K \n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 576   \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K \n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 576   \n",
      "20 | output_layer                       | Linear                          | 119   \n",
      "----------------------------------------------------------------------------------------\n",
      "22.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "22.0 K    Total params\n",
      "0.088     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad12600f1c0744b6b40c9a02078a0fb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fit network\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "18e07593-7ecb-47e9-9e6b-d17789cc384d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter 튜닝\n",
    "# import pickle\n",
    "\n",
    "# from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "\n",
    "# # create study\n",
    "# study = optimize_hyperparameters(\n",
    "#     train_dataloader,\n",
    "#     val_dataloader,\n",
    "#     model_path=\"optuna_test\",\n",
    "#     n_trials=200,\n",
    "#     max_epochs=50,\n",
    "#     gradient_clip_val_range=(0.01, 1.0),\n",
    "#     hidden_size_range=(8, 128),\n",
    "#     hidden_continuous_size_range=(8, 128),\n",
    "#     attention_head_size_range=(1, 4),\n",
    "#     learning_rate_range=(0.001, 0.1),\n",
    "#     dropout_range=(0.1, 0.3),\n",
    "#     trainer_kwargs=dict(limit_train_batches=30),\n",
    "#     reduce_on_plateau_patience=4,\n",
    "#     use_learning_rate_finder=False,  # use Optuna to find ideal learning rate or use in-built learning rate finder\n",
    "# )\n",
    "\n",
    "# # save study results - also we can resume tuning at a later point in time\n",
    "# with open(\"test_study.pkl\", \"wb\") as fout:\n",
    "#     pickle.dump(study, fout)\n",
    "\n",
    "# # show best hyperparameters\n",
    "# print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "729ecac7-07ff-4d1f-8281-217c77d4a8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model according to the validation loss\n",
    "# (given that we use early stopping, this is not necessarily the last epoch)\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4ed4e1fb-8bf8-4022-aa70-f2bbabe063e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw predictions are a dictionary from which all kind of information including quantiles can be extracted\n",
    "#raw_predictions, x = best_tft.predict(val_dataloader, mode=\"raw\", return_x=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "cd3a7713-0854-4e1c-bd83-0450cf4398d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for idx in range(1):  # plot 10 examples\n",
    "#    best_tft.plot_prediction(x, raw_predictions, idx=idx, add_loss_to_title=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0f0f7df9-dd27-4cea-8029-dfdaebb4c20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = df[lambda x: x.time_idx > x.time_idx.max() - max_prediction_length]\n",
    "val_df = val_df[[date_var, target_var] + store_list].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "58295fc2-79e4-47fd-b66e-da4e59fdf5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictions = best_tft.predict(val_dataloader, mode=\"prediction\", return_x=False)\n",
    "val_predictions = pd.DataFrame(val_predictions.reshape(-1,1).numpy(), columns=['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c4d36d59-e52a-48ea-a691-8df3aea7fc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.concat([val_df, val_predictions], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0821885c-b6a1-4ad0-b8f1-837c5b978aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Store</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-02</td>\n",
       "      <td>1.802477e+06</td>\n",
       "      <td>1</td>\n",
       "      <td>1.562023e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-08</td>\n",
       "      <td>1.592410e+06</td>\n",
       "      <td>1</td>\n",
       "      <td>1.569455e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-19</td>\n",
       "      <td>1.508069e+06</td>\n",
       "      <td>1</td>\n",
       "      <td>1.555362e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>1.493660e+06</td>\n",
       "      <td>1</td>\n",
       "      <td>1.569398e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-11-05</td>\n",
       "      <td>1.611096e+06</td>\n",
       "      <td>1</td>\n",
       "      <td>1.568334e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>2012-10-08</td>\n",
       "      <td>5.387135e+05</td>\n",
       "      <td>9</td>\n",
       "      <td>5.591736e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>2012-10-19</td>\n",
       "      <td>5.420094e+05</td>\n",
       "      <td>9</td>\n",
       "      <td>5.592157e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>5.497315e+05</td>\n",
       "      <td>9</td>\n",
       "      <td>5.571978e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>2012-12-10</td>\n",
       "      <td>5.584648e+05</td>\n",
       "      <td>9</td>\n",
       "      <td>5.538488e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>2012-11-05</td>\n",
       "      <td>5.925723e+05</td>\n",
       "      <td>9</td>\n",
       "      <td>5.531148e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>315 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Weekly_Sales Store          pred\n",
       "0   2012-10-02  1.802477e+06     1  1.562023e+06\n",
       "1   2012-10-08  1.592410e+06     1  1.569455e+06\n",
       "2   2012-10-19  1.508069e+06     1  1.555362e+06\n",
       "3   2012-10-26  1.493660e+06     1  1.569398e+06\n",
       "4   2012-11-05  1.611096e+06     1  1.568334e+06\n",
       "..         ...           ...   ...           ...\n",
       "310 2012-10-08  5.387135e+05     9  5.591736e+05\n",
       "311 2012-10-19  5.420094e+05     9  5.592157e+05\n",
       "312 2012-10-26  5.497315e+05     9  5.571978e+05\n",
       "313 2012-12-10  5.584648e+05     9  5.538488e+05\n",
       "314 2012-11-05  5.925723e+05     9  5.531148e+05\n",
       "\n",
       "[315 rows x 4 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a8f51ba2-854f-46a0-b4ac-c8942817119b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select last 24 months from data (max_encoder_length is 24)\n",
    "encoder_data = df[lambda x: x.time_idx > x.time_idx.max() - max_encoder_length]\n",
    "\n",
    "# select last known data point and create decoder data from it by repeating it and incrementing the month\n",
    "# in a real world dataset, we should not just forward fill the covariates but specify them to account\n",
    "# for changes in special days and prices (which you absolutely should do but we are too lazy here)\n",
    "last_data = df[lambda x: x.time_idx == x.time_idx.max()]\n",
    "\n",
    "\n",
    "decoder_data = pd.concat(\n",
    "    [last_data.assign(date_var = lambda x: x[date_var] + timedelta(days=i),\n",
    "                      time_idx = lambda x: x.time_idx + i) \n",
    "                    for i in range(1, max_prediction_length + 1)], ignore_index=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8d3f2b3c-b6e9-4680-bd41-ccff060dd42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Holiday_Flag</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Date</th>\n",
       "      <th>Store</th>\n",
       "      <th>dummy</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>week</th>\n",
       "      <th>log_Weekly_Sales</th>\n",
       "      <th>avg_Weekly_Sales_by_Store</th>\n",
       "      <th>date_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.126709</td>\n",
       "      <td>0.529297</td>\n",
       "      <td>1.315430</td>\n",
       "      <td>-0.759766</td>\n",
       "      <td>-0.27417</td>\n",
       "      <td>1.573073e+06</td>\n",
       "      <td>2012-12-10</td>\n",
       "      <td>1</td>\n",
       "      <td>dummy</td>\n",
       "      <td>143</td>\n",
       "      <td>50</td>\n",
       "      <td>14.268541</td>\n",
       "      <td>1.573073e+06</td>\n",
       "      <td>2012-12-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.831543</td>\n",
       "      <td>2.419922</td>\n",
       "      <td>-1.028320</td>\n",
       "      <td>-0.563965</td>\n",
       "      <td>-0.27417</td>\n",
       "      <td>1.713889e+06</td>\n",
       "      <td>2012-12-10</td>\n",
       "      <td>10</td>\n",
       "      <td>dummy</td>\n",
       "      <td>143</td>\n",
       "      <td>50</td>\n",
       "      <td>14.354276</td>\n",
       "      <td>1.713889e+06</td>\n",
       "      <td>2012-12-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.502930</td>\n",
       "      <td>0.529297</td>\n",
       "      <td>1.404297</td>\n",
       "      <td>-1.046875</td>\n",
       "      <td>-0.27417</td>\n",
       "      <td>1.311965e+06</td>\n",
       "      <td>2012-12-10</td>\n",
       "      <td>11</td>\n",
       "      <td>dummy</td>\n",
       "      <td>143</td>\n",
       "      <td>50</td>\n",
       "      <td>14.087037</td>\n",
       "      <td>1.311965e+06</td>\n",
       "      <td>2012-12-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.601074</td>\n",
       "      <td>2.419922</td>\n",
       "      <td>-1.028320</td>\n",
       "      <td>1.169922</td>\n",
       "      <td>-0.27417</td>\n",
       "      <td>9.349175e+05</td>\n",
       "      <td>2012-12-10</td>\n",
       "      <td>12</td>\n",
       "      <td>dummy</td>\n",
       "      <td>143</td>\n",
       "      <td>50</td>\n",
       "      <td>13.748214</td>\n",
       "      <td>9.349175e+05</td>\n",
       "      <td>2012-12-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.302002</td>\n",
       "      <td>0.954590</td>\n",
       "      <td>-1.028320</td>\n",
       "      <td>-1.268555</td>\n",
       "      <td>-0.27417</td>\n",
       "      <td>1.999080e+06</td>\n",
       "      <td>2012-12-10</td>\n",
       "      <td>13</td>\n",
       "      <td>dummy</td>\n",
       "      <td>143</td>\n",
       "      <td>50</td>\n",
       "      <td>14.508198</td>\n",
       "      <td>1.999080e+06</td>\n",
       "      <td>2012-12-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>0.302979</td>\n",
       "      <td>0.529297</td>\n",
       "      <td>1.332031</td>\n",
       "      <td>-1.374023</td>\n",
       "      <td>-0.27417</td>\n",
       "      <td>3.253454e+05</td>\n",
       "      <td>2012-12-10</td>\n",
       "      <td>5</td>\n",
       "      <td>dummy</td>\n",
       "      <td>149</td>\n",
       "      <td>50</td>\n",
       "      <td>12.692643</td>\n",
       "      <td>3.253454e+05</td>\n",
       "      <td>2012-12-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>0.258789</td>\n",
       "      <td>0.529297</td>\n",
       "      <td>1.357422</td>\n",
       "      <td>-1.424805</td>\n",
       "      <td>-0.27417</td>\n",
       "      <td>1.459397e+06</td>\n",
       "      <td>2012-12-10</td>\n",
       "      <td>6</td>\n",
       "      <td>dummy</td>\n",
       "      <td>149</td>\n",
       "      <td>50</td>\n",
       "      <td>14.193534</td>\n",
       "      <td>1.459397e+06</td>\n",
       "      <td>2012-12-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>-1.042969</td>\n",
       "      <td>0.874023</td>\n",
       "      <td>0.696777</td>\n",
       "      <td>-0.234985</td>\n",
       "      <td>-0.27417</td>\n",
       "      <td>5.034639e+05</td>\n",
       "      <td>2012-12-10</td>\n",
       "      <td>7</td>\n",
       "      <td>dummy</td>\n",
       "      <td>149</td>\n",
       "      <td>50</td>\n",
       "      <td>13.129268</td>\n",
       "      <td>5.034639e+05</td>\n",
       "      <td>2012-12-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>-0.305420</td>\n",
       "      <td>0.529297</td>\n",
       "      <td>1.408203</td>\n",
       "      <td>-1.533203</td>\n",
       "      <td>-0.27417</td>\n",
       "      <td>9.275120e+05</td>\n",
       "      <td>2012-12-10</td>\n",
       "      <td>8</td>\n",
       "      <td>dummy</td>\n",
       "      <td>149</td>\n",
       "      <td>50</td>\n",
       "      <td>13.740261</td>\n",
       "      <td>9.275120e+05</td>\n",
       "      <td>2012-12-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>-0.030914</td>\n",
       "      <td>0.529297</td>\n",
       "      <td>1.411133</td>\n",
       "      <td>-1.624023</td>\n",
       "      <td>-0.27417</td>\n",
       "      <td>5.584648e+05</td>\n",
       "      <td>2012-12-10</td>\n",
       "      <td>9</td>\n",
       "      <td>dummy</td>\n",
       "      <td>149</td>\n",
       "      <td>50</td>\n",
       "      <td>13.232947</td>\n",
       "      <td>5.584648e+05</td>\n",
       "      <td>2012-12-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>315 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Temperature  Fuel_Price       CPI  Unemployment  Holiday_Flag  \\\n",
       "0       0.126709    0.529297  1.315430     -0.759766      -0.27417   \n",
       "1       0.831543    2.419922 -1.028320     -0.563965      -0.27417   \n",
       "2       0.502930    0.529297  1.404297     -1.046875      -0.27417   \n",
       "3       0.601074    2.419922 -1.028320      1.169922      -0.27417   \n",
       "4      -0.302002    0.954590 -1.028320     -1.268555      -0.27417   \n",
       "..           ...         ...       ...           ...           ...   \n",
       "310     0.302979    0.529297  1.332031     -1.374023      -0.27417   \n",
       "311     0.258789    0.529297  1.357422     -1.424805      -0.27417   \n",
       "312    -1.042969    0.874023  0.696777     -0.234985      -0.27417   \n",
       "313    -0.305420    0.529297  1.408203     -1.533203      -0.27417   \n",
       "314    -0.030914    0.529297  1.411133     -1.624023      -0.27417   \n",
       "\n",
       "     Weekly_Sales       Date Store  dummy  time_idx week  log_Weekly_Sales  \\\n",
       "0    1.573073e+06 2012-12-10     1  dummy       143   50         14.268541   \n",
       "1    1.713889e+06 2012-12-10    10  dummy       143   50         14.354276   \n",
       "2    1.311965e+06 2012-12-10    11  dummy       143   50         14.087037   \n",
       "3    9.349175e+05 2012-12-10    12  dummy       143   50         13.748214   \n",
       "4    1.999080e+06 2012-12-10    13  dummy       143   50         14.508198   \n",
       "..            ...        ...   ...    ...       ...  ...               ...   \n",
       "310  3.253454e+05 2012-12-10     5  dummy       149   50         12.692643   \n",
       "311  1.459397e+06 2012-12-10     6  dummy       149   50         14.193534   \n",
       "312  5.034639e+05 2012-12-10     7  dummy       149   50         13.129268   \n",
       "313  9.275120e+05 2012-12-10     8  dummy       149   50         13.740261   \n",
       "314  5.584648e+05 2012-12-10     9  dummy       149   50         13.232947   \n",
       "\n",
       "     avg_Weekly_Sales_by_Store   date_var  \n",
       "0                 1.573073e+06 2012-12-11  \n",
       "1                 1.713889e+06 2012-12-11  \n",
       "2                 1.311965e+06 2012-12-11  \n",
       "3                 9.349175e+05 2012-12-11  \n",
       "4                 1.999080e+06 2012-12-11  \n",
       "..                         ...        ...  \n",
       "310               3.253454e+05 2012-12-17  \n",
       "311               1.459397e+06 2012-12-17  \n",
       "312               5.034639e+05 2012-12-17  \n",
       "313               9.275120e+05 2012-12-17  \n",
       "314               5.584648e+05 2012-12-17  \n",
       "\n",
       "[315 rows x 14 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0ab855fc-b418-4e25-8998-3ee9a653c288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select last 24 months from data (max_encoder_length is 24)\n",
    "encoder_data = df[lambda x: x.time_idx > x.time_idx.max() - max_encoder_length]\n",
    "\n",
    "# select last known data point and create decoder data from it by repeating it and incrementing the month\n",
    "# in a real world dataset, we should not just forward fill the covariates but specify them to account\n",
    "# for changes in special days and prices (which you absolutely should do but we are too lazy here)\n",
    "last_data = df[lambda x: x.time_idx == x.time_idx.max()]\n",
    "\n",
    "if unit == 'day':\n",
    "    decoder_data = pd.concat(\n",
    "    [last_data.assign(date_var = lambda x: x[date_var] + timedelta(days=i),\n",
    "                      time_idx = lambda x: x.time_idx + i) \n",
    "                    for i in range(1, max_prediction_length + 1)], ignore_index=True, )\n",
    "elif unit == 'week':\n",
    "    decoder_data = pd.concat(\n",
    "    [last_data.assign(date_var = lambda x: x[date_var] + timedelta(days=7*i),\n",
    "                      time_idx = lambda x: x.time_idx + i) \n",
    "                    for i in range(1, max_prediction_length + 1)], ignore_index=True, )\n",
    "elif unit == 'month':\n",
    "    decoder_data = pd.concat([last_data.assign(date_var = lambda x: x[date_var] + pd.offsets.MonthBegin(i),\n",
    "                      time_idx = lambda x: x.time_idx + i) \n",
    "                    for i in range(1, max_prediction_length + 1)], ignore_index=True, )\n",
    "\n",
    "#fake date_var 삽입 필요\n",
    "decoder_data.loc[:, date_var] = decoder_data['date_var']\n",
    "decoder_data.drop('date_var', axis=1, inplace=True)\n",
    "decoder_data.sort_values(store_list, inplace=True)\n",
    "\n",
    "# add additional features\n",
    "if unit == 'day':\n",
    "    decoder_data[unit] = decoder_data[date_var].dt.day.astype(str).astype(\"category\")\n",
    "elif unit == 'week':\n",
    "    decoder_data[unit] = decoder_data[date_var].dt.isocalendar().week.astype(str).astype(\"category\")  # categories have be strings\n",
    "elif unit == 'month':\n",
    "    decoder_data[unit] = decoder_data[date_var].dt.month.astype(str).astype(\"category\")  # categories have be strings\n",
    "\n",
    "# combine encoder and decoder data\n",
    "new_prediction_data = pd.concat([encoder_data, decoder_data], ignore_index=True)\n",
    "#매우 중요\n",
    "new_prediction_data.sort_values(store_list, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "232d6d2a-02db-4e8b-9f2d-d7875fc63d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_raw_predictions, new_x = best_tft.predict(new_prediction_data, mode=\"raw\", return_x=True)\n",
    "# for idx in range(1):  # plot 10 examples\n",
    "#     best_tft.plot_prediction(new_x, new_raw_predictions, idx=idx, show_future_observed=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "006e5dae-d1c2-4e86-b717-6f306458ad5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_tft.predict(new_prediction_data, mode=\"prediction\", return_x=False)\n",
    "predictions = pd.DataFrame(predictions.reshape(-1,1).numpy(), columns=['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "aaf017e0-af1e-4107-813c-25caf72885ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = decoder_data[[date_var] + store_list].reset_index(drop=True)\n",
    "pred_df = pd.concat([pred_df, predictions], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6db9b957-edb0-4905-9049-0f538b276623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Store</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-12-17</td>\n",
       "      <td>1</td>\n",
       "      <td>1.594529e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1.495416e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-21</td>\n",
       "      <td>1</td>\n",
       "      <td>1.568118e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-14</td>\n",
       "      <td>1</td>\n",
       "      <td>1.444036e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-28</td>\n",
       "      <td>1</td>\n",
       "      <td>1.366658e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>2013-01-21</td>\n",
       "      <td>9</td>\n",
       "      <td>5.607846e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>9</td>\n",
       "      <td>4.920490e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>2012-12-17</td>\n",
       "      <td>9</td>\n",
       "      <td>4.487731e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>2012-12-24</td>\n",
       "      <td>9</td>\n",
       "      <td>5.499174e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>2013-01-28</td>\n",
       "      <td>9</td>\n",
       "      <td>5.518616e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>315 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date Store          pred\n",
       "0   2012-12-17     1  1.594529e+06\n",
       "1   2012-12-31     1  1.495416e+06\n",
       "2   2013-01-21     1  1.568118e+06\n",
       "3   2013-01-14     1  1.444036e+06\n",
       "4   2013-01-28     1  1.366658e+06\n",
       "..         ...   ...           ...\n",
       "310 2013-01-21     9  5.607846e+05\n",
       "311 2013-01-07     9  4.920490e+05\n",
       "312 2012-12-17     9  4.487731e+05\n",
       "313 2012-12-24     9  5.499174e+05\n",
       "314 2013-01-28     9  5.518616e+05\n",
       "\n",
       "[315 rows x 3 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91af24fb-d601-492e-b2ad-3ef6db3a542f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
